/*
 * Copyright 2020 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     https://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package com.google.mlkit.md.camera

import android.Manifest
import android.content.Context
import android.content.pm.PackageManager
import android.graphics.ImageFormat
import android.hardware.camera2.*
import android.media.Image
import android.media.ImageReader
import android.os.Handler
import android.os.HandlerThread
import android.util.Log
import android.util.Size
import android.view.Surface
import android.view.SurfaceHolder
import androidx.core.app.ActivityCompat
import com.google.android.odml.image.MediaMlImageBuilder
import com.google.android.odml.image.MlImage
import com.google.mlkit.md.R
import com.google.mlkit.md.Utils
import com.google.mlkit.md.settings.PreferenceUtils
import com.google.mlkit.md.utils.OrientationLiveData
import kotlinx.coroutines.runBlocking
import kotlinx.coroutines.suspendCancellableCoroutine
import kotlinx.coroutines.sync.Mutex
import kotlinx.coroutines.sync.withLock
import java.io.IOException
import java.util.*
import kotlin.coroutines.resume
import kotlin.coroutines.resumeWithException
import kotlin.coroutines.suspendCoroutine
import kotlin.math.abs

/**
 * Manages the camera and allows UI updates on top of it (e.g. overlaying extra Graphics). This
 * receives preview frames from the camera at a specified rate, sends those frames to detector as
 * fast as it is able to process.
 *
 *
 * This camera source makes a best effort to manage processing on preview frames as fast as
 * possible, while at the same time minimizing lag. As such, frames may be dropped if the detector
 * is unable to keep up with the rate of frames generated by the camera.
 */

class Camera2APISource(private val graphicOverlay: GraphicOverlay): CameraSource() {

    private val context: Context = graphicOverlay.context

    /** Detects, characterizes, and connects to a CameraDevice (used for all camera operations) */
    private val cameraManager: CameraManager by lazy {
        getCameraManager(context)
    }

    /** [cameraId] corresponding to the provided Camera facing back property */
    private val cameraId: String by lazy {
        getCameraId(context)
    }

    /** [CameraCharacteristics] corresponding to the provided Camera ID */
    private val characteristics: CameraCharacteristics by lazy {
        getCameraCharacteristics(context)
    }

    /** The [CameraDevice] that will be used for preview */
    private var camera: CameraDevice? = null

    /** The [ImageReader] that will used for reading image frame buffers */
    private var imageReader: ImageReader? = null

    /** The [CaptureRequest.Builder] that will be used for session */
    private var captureRequest: CaptureRequest.Builder? = null

    /** Internal reference to the ongoing [CameraCaptureSession] configured with our parameters */
    private var session: CameraCaptureSession? = null

    /** [HandlerThread] where all camera operations run */
    private val cameraThread = HandlerThread("CameraThread").apply { start() }

    /** [Handler] corresponding to [cameraThread] */
    private val cameraHandler = Handler(cameraThread.looper)

    /** [HandlerThread] where all buffer reading operations run */
    private val imageReaderThread = HandlerThread("imageReaderThread").apply { start() }

    /** [Handler] corresponding to [imageReaderThread] */
    private val imageReaderHandler = Handler(imageReaderThread.looper)

    /** [OrientationLiveData] correspond to current device orientation relative to the [camera] or listening to the changes in it */
    private val relativeOrientation: OrientationLiveData by lazy {
        OrientationLiveData(context, characteristics)
    }

    /** [Observer] for listening the changes in the [relativeOrientation] */
    private val orientationObserver  = androidx.lifecycle.Observer<Int> { rotation ->
        Log.d(TAG, "Orientation changed: $rotation")
    }

    /** [Size] that is currently in use by the [camera] */
    private var previewSize: Size? = null

    /** [Thread] for detecting & processing [imageReader] frames */
    private var processingThread: Thread? = null

    /** [FrameProcessingRunnable] associated with the [processingThread] */
    private val processingRunnable = FrameProcessingRunnable()

    /** [Object] to lock the [frameProcessor] operations */
    private val processorLock = Object()

    /** [Mutex] to lock the CoroutineScope operations */
    private val mutex = Mutex()

    /** [FrameProcessor] to process the frames received inside [processingRunnable] */
    private var frameProcessor: FrameProcessor? = null

    /**
     * Start the camera preview on the provided surface and process images through image reader buffer
     *
     * @param captureRequest the capture request builder to use for the session.
     * @param imageReader the image reader for receiving the preview images for processing.
     * @param session the configured camera capture session for the camera device.
     *
     * @throws Exception if the supplied surface holder could not be used as the preview display.
     */

    @Throws(Exception::class)
    private fun startPreview(captureRequest: CaptureRequest.Builder, imageReader: ImageReader, session: CameraCaptureSession){
        // This will keep sending the capture request as frequently as possible until the
        // session is torn down or session.stopRepeating() is called
        session.setRepeatingRequest(captureRequest.build(), null, cameraHandler)

        //Setup listener for receiving the preview frames for processing
        imageReader.setOnImageAvailableListener({
            try {
                it.acquireNextImage()?.let {image ->
                    val rotation = relativeOrientation.value ?: 0
                    processingRunnable.setNextFrame(image, rotation)
                }
            }
            catch (e: IllegalStateException){
                e.printStackTrace()
                Log.e(TAG, "${e.message} At acquire next image")
            }
        }, imageReaderHandler)

    }

    /**
     * Update the camera preview with the changes in the capture request builder
     *
     * @param captureRequest the capture request builder to use for the session.
     * @param session the configured camera capture session for the camera device.
     *
     * @throws Exception if the supplied surface holder could not be used as the preview display.
     *
     * */
    @Throws(Exception::class)
    private fun updatePreview(captureRequest: CaptureRequest.Builder, session: CameraCaptureSession){
        session.setRepeatingRequest(captureRequest.build(), null, cameraHandler)
    }

    private fun updateFlashMode(enabled: Boolean) {
        val flashAvailable = characteristics.get(CameraCharacteristics.FLASH_INFO_AVAILABLE) as Boolean
        if(flashAvailable){
            session?.let {session ->
                captureRequest?.let { captureRequest ->
                    captureRequest.set(CaptureRequest.FLASH_MODE,
                        if (enabled) CaptureRequest.FLASH_MODE_TORCH else CaptureRequest.FLASH_MODE_OFF)
                    updatePreview(captureRequest, session)
                }
            }
        }
    }

    /**
     * Opens the camera and applies the user settings.
     *
     * @throws Exception if camera cannot be found or preview cannot be processed.
     */
    @Throws(Exception::class)
    private suspend fun createCamera(): CameraDevice = suspendCancellableCoroutine {cont ->

        if (ActivityCompat.checkSelfPermission(context, Manifest.permission.CAMERA) != PackageManager.PERMISSION_GRANTED) {
            if (cont.isActive) cont.resumeWithException(IOException("Camera permission not granted"))
        }

        cameraManager.openCamera(cameraId, object : CameraDevice.StateCallback() {
            override fun onOpened(camera: CameraDevice) = cont.resume(camera)

            override fun onDisconnected(camera: CameraDevice) {
                val exec = IOException("Camera $cameraId has been disconnected")
                Log.e(TAG, exec.message, exec)
                if (cont.isActive) cont.resumeWithException(exec)
            }

            override fun onError(camera: CameraDevice, error: Int) {
                val msg = when (error) {
                    ERROR_CAMERA_DEVICE -> "Fatal (device)"
                    ERROR_CAMERA_DISABLED -> "Device policy"
                    ERROR_CAMERA_IN_USE -> "Camera in use"
                    ERROR_CAMERA_SERVICE -> "Fatal (service)"
                    ERROR_MAX_CAMERAS_IN_USE -> "Maximum cameras in use"
                    else -> "Unknown"
                }
                val exc = IOException("Camera $cameraId error: ($error) $msg")
                Log.e(TAG, exc.message, exc)
                if(cont.isActive) cont.resumeWithException(exc)
            }

        }, cameraHandler)

    }

    /**
     * Starts a [CameraCaptureSession] and returns the configured session
     *
     * @throws Exception if session cannot be created.
     */
    @Throws(Exception::class)
    private suspend fun createCaptureSession(device: CameraDevice, targets: List<Surface>, handler: Handler? = null): CameraCaptureSession = suspendCoroutine{ cont ->

        // Create a capture session using the predefined targets; this also involves defining the
        // session state callback to be notified of when the session is ready
        device.createCaptureSession(targets, object : CameraCaptureSession.StateCallback() {

            override fun onConfigured(session: CameraCaptureSession) = cont.resume(session)

            override fun onConfigureFailed(session: CameraCaptureSession) {
                val exc = RuntimeException("Camera ${device.id} session configuration failed")
                Log.e(TAG, exc.message, exc)
                cont.resumeWithException(exc)
            }
        }, handler)
    }

    /**
     * Get the most suitable [CameraSizePair] from aspect ratio perspective.
     *
     * @throws Exception if cannot find a suitable size.
     */
    @Throws(Exception::class)
    private fun getPreviewAndPictureSize(cameraSource: CameraSource): CameraSizePair  {

        // Gives priority to the preview size specified by the user if exists.
        val sizePair: CameraSizePair = PreferenceUtils.getUserSpecifiedPreviewSize(context) ?: run {
            // Camera preview size is based on the landscape mode, so we need to also use the aspect
            // ration of display in the same mode for comparison.
            val displayAspectRatioInLandscape: Float =
                if (Utils.isPortraitMode(graphicOverlay.context)) {
                    graphicOverlay.height.toFloat() / graphicOverlay.width
                } else {
                    graphicOverlay.width.toFloat() / graphicOverlay.height
                }
            selectSizePair(cameraSource, displayAspectRatioInLandscape)
        } ?: throw IOException("Could not find suitable preview size.")

        sizePair.preview.let {
            Log.v(TAG, "Camera preview size: $it")
            PreferenceUtils.saveStringPreference(context, R.string.pref_key_rear_camera_preview_size, it.toString())
        }

        sizePair.picture?.let { pictureSize ->
            Log.v(TAG, "Camera picture size: $pictureSize")
            PreferenceUtils.saveStringPreference(
                context, R.string.pref_key_rear_camera_picture_size, pictureSize.toString()
            )
        }
        return sizePair
    }

    //Camera source overrides

    override fun getSupportedPreviewSizes(): Array<Size> = characteristics.get(CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP)!!.getOutputSizes(SurfaceHolder::class.java)

    override fun getSupportedPictureSizes(): Array<Size> = characteristics.get(CameraCharacteristics.SCALER_STREAM_CONFIGURATION_MAP)!!.getOutputSizes(IMAGE_FORMAT)

    override fun setFrameProcessor(processor: FrameProcessor) {
        graphicOverlay.clear()
        synchronized(processorLock) {
            frameProcessor?.stop()
            frameProcessor = processor
        }
    }

    override fun setFlashStatus(status: Boolean){
        if (status){
            updateFlashMode(true)
        }
        else{
            updateFlashMode(false)
        }
    }

    override fun getSelectedPreviewSize() = previewSize

    override fun start(surfaceHolder: SurfaceHolder) {
        runBlocking {
            mutex.withLock {

                if (camera != null) return@withLock

                camera = createCamera().also { cameraDevice ->
                    getPreviewAndPictureSize(this@Camera2APISource).preview.let { previewSize ->
                        imageReader = ImageReader.newInstance(previewSize.width, previewSize.height, IMAGE_FORMAT, IMAGE_BUFFER_SIZE).also { imageReader ->
                            session = createCaptureSession(cameraDevice, listOf(surfaceHolder.surface, imageReader.surface), cameraHandler).also { cameraCaptureSession ->
                                captureRequest = cameraDevice.createCaptureRequest(CameraDevice.TEMPLATE_PREVIEW).apply {
                                    addTarget(surfaceHolder.surface)
                                    addTarget(imageReader.surface)
                                    startPreview( this, imageReader, cameraCaptureSession)
                                }
                            }
                        }
                    }
                    processingThread = Thread(processingRunnable).apply {
                        processingRunnable.setActive(true)
                        start()
                    }
                    relativeOrientation.observeForever(orientationObserver)
                }

            }
        }
    }

    override fun stop() {
        runBlocking {
            mutex.withLock {
                Log.d(TAG, "Stop is called")
                processingRunnable.setActive(false)
                processingThread?.let {
                    try {
                        // Waits for the thread to complete to ensure that we can't have multiple threads executing
                        // at the same time (i.e., which would happen if we called start too quickly after stop).
                        it.join()
                    } catch (e: InterruptedException) {
                        Log.e(TAG, "Frame processing thread interrupted on stop.")
                    }
                    processingThread = null
                }

                // Remove the reference image reader buffer & orientation change observer, since it will no longer be in use.
                imageReader?.let {
                    it.setOnImageAvailableListener(null, null)
                    imageReader = null
                }

                relativeOrientation.removeObserver(orientationObserver)

                camera?.let {
                    it.close()
                    camera = null
                }
            }
        }
    }

    override fun release() {
        graphicOverlay.clear()
        synchronized(processorLock) {
            stop()
            frameProcessor?.stop()
            cameraThread.quitSafely()
            imageReaderThread.quitSafely()
        }
    }

    /**
     * This runnable controls access to the underlying receiver, calling it to process frames when
     * available from the camera. This is designed to run detection on frames as fast as possible
     * (i.e., without unnecessary context switching or waiting on the next frame).
     *
     *
     * While detection is running on a frame, new frames may be received from the camera. As these
     * frames come in, the most recent frame is held onto as pending. As soon as detection and its
     * associated processing is done for the previous frame, detection on the mostly recently received
     * frame will immediately start on the same thread.
     */
    private inner class FrameProcessingRunnable : Runnable {

        // This lock guards all of the member variables below.
        private val lock = Object()
        private var active = true

        // These pending variables hold the state associated with the new frame awaiting processing.
        private var pendingFrame: Image? = null
        private var pendingFrameRotation: Int = 0

        /** Marks the runnable as active/not active. Signals any blocked threads to continue.  */
        fun setActive(active: Boolean) {
            synchronized(lock) {
                this.active = active
                lock.notifyAll()
            }
        }

        /**
         * Sets the frame data received from the camera. This adds the previous unused frame buffer (if
         * present) back to the camera, and keeps a pending reference to the frame data for future use.
         */
        fun setNextFrame(image: Image, rotation: Int) {
            synchronized(lock) {
                pendingFrame?.let {
                    it.close()
                    pendingFrame = null
                }

                pendingFrame = image
                pendingFrameRotation = rotation

                // Notify the processor thread if it is waiting on the next frame (see below).
                lock.notifyAll()
            }
        }

        /**
         * As long as the processing thread is active, this executes detection on frames continuously.
         * The next pending frame is either immediately available or hasn't been received yet. Once it
         * is available, we transfer the frame info to local variables and run detection on that frame.
         * It immediately loops back for the next frame without pausing.
         *
         *
         * If detection takes longer than the time in between new frames from the camera, this will
         * mean that this loop will run without ever waiting on a frame, avoiding any context switching
         * or frame acquisition time latency.
         *
         *
         * If you find that this is using more CPU than you'd like, you should probably decrease the
         * FPS setting above to allow for some idle time in between frames.
         */
        override fun run() {
            var data: MlImage?

            while (true) {
                synchronized(lock) {
                    while (active && pendingFrame == null) {
                        try {
                            // Wait for the next frame to be received from the camera, since we don't have it yet.
                            lock.wait()
                        } catch (e: InterruptedException) {
                            Log.e(TAG, "Frame processing loop terminated.", e)
                            return
                        }
                    }

                    if (!active) {
                        // Exit the loop once this camera source is stopped or released.  We check this here,
                        // immediately after the wait() above, to handle the case where setActive(false) had
                        // been called, triggering the termination of this loop.
                        return
                    }

                    // Hold onto the frame data locally, so that we can use this for detection
                    // below.  We need to clear pendingFrameData to ensure that this buffer isn't
                    // recycled back to the camera before we are done using that data.
                    data = pendingFrame?.let {
                        MediaMlImageBuilder(it)
                            .setRotation(pendingFrameRotation)
                            .build()
                    }
                    pendingFrame = null

                }

                try {
                    synchronized(processorLock) {
                        data?.let {
                            if(frameProcessor?.process(it, graphicOverlay) == true){
                                //Do nothing as frame processor accepted the image for processing
                                // and it will close the image once the detection gets completed on it
                            }
                            else{
                                //Close image immediately because either frame processor is
                                // not set or it's currently busy processing previous image
                                it.close()
                            }
                        }
                    }
                } catch (t: Exception) {
                    Log.e(TAG, "Exception thrown from receiver.", t)
                    //precautionary image close request in-case there is an exception occurred
                    // while submitting the image to the frame processor
                    data?.close()
                }
            }
        }
    }

    companion object {

        const val CAMERA_FACING_BACK = CameraCharacteristics.LENS_FACING_BACK
        const val IMAGE_FORMAT = ImageFormat.YUV_420_888

        private const val TAG = "Camera2APISource"

        /** Maximum number of images that will be held in the reader's buffer */
        private const val IMAGE_BUFFER_SIZE: Int = 3

        private const val MIN_CAMERA_PREVIEW_WIDTH = 400
        private const val MAX_CAMERA_PREVIEW_WIDTH = 1300
        private const val DEFAULT_REQUESTED_CAMERA_PREVIEW_WIDTH = 640
        private const val DEFAULT_REQUESTED_CAMERA_PREVIEW_HEIGHT = 360

        private fun getCameraManager(context: Context) = context.getSystemService(Context.CAMERA_SERVICE) as CameraManager

        private fun getCameraId(context: Context): String {
            val cameraManager = getCameraManager(context)
            cameraManager.cameraIdList.forEach {
                val characteristics = cameraManager.getCameraCharacteristics(it)
                if (characteristics.get(CameraCharacteristics.LENS_FACING) == CAMERA_FACING_BACK){
                    return it
                }
            }
            throw IOException("No Camera found matching the back facing lens $CAMERA_FACING_BACK")
        }

        fun getCameraCharacteristics(context: Context) = getCameraManager(context).getCameraCharacteristics(getCameraId(context))

        /**
         * Selects the most suitable preview and picture size, given the display aspect ratio in landscape
         * mode.
         *
         *
         * It's firstly trying to pick the one that has closest aspect ratio to display view with its
         * width be in the specified range [[.MIN_CAMERA_PREVIEW_WIDTH], [ ][.MAX_CAMERA_PREVIEW_WIDTH]]. If there are multiple candidates, choose the one having longest
         * width.
         *
         *
         * If the above looking up failed, chooses the one that has the minimum sum of the differences
         * between the desired values and the actual values for width and height.
         *
         *
         * Even though we only need to find the preview size, it's necessary to find both the preview
         * size and the picture size of the camera together, because these need to have the same aspect
         * ratio. On some hardware, if you would only set the preview size, you will get a distorted
         * image.
         *
         * @param cameraSource the selected camera source to select a preview size from
         * @return the selected preview and picture size pair
         */
        private fun selectSizePair(cameraSource: CameraSource, displayAspectRatioInLandscape: Float): CameraSizePair? {
            val validPreviewSizes = Utils.generateValidPreviewSizeList(cameraSource)

            var selectedPair: CameraSizePair? = null
            // Picks the preview size that has closest aspect ratio to display view.
            var minAspectRatioDiff = Float.MAX_VALUE

            for (sizePair in validPreviewSizes) {
                val previewSize = sizePair.preview
                if (previewSize.width < MIN_CAMERA_PREVIEW_WIDTH || previewSize.width > MAX_CAMERA_PREVIEW_WIDTH) {
                    continue
                }

                val previewAspectRatio = previewSize.width.toFloat() / previewSize.height.toFloat()
                val aspectRatioDiff = abs(displayAspectRatioInLandscape - previewAspectRatio)
                if (abs(aspectRatioDiff - minAspectRatioDiff) < Utils.ASPECT_RATIO_TOLERANCE) {
                    if (selectedPair == null || selectedPair.preview.width < sizePair.preview.width) {
                        selectedPair = sizePair
                    }
                } else if (aspectRatioDiff < minAspectRatioDiff) {
                    minAspectRatioDiff = aspectRatioDiff
                    selectedPair = sizePair
                }
            }

            if (selectedPair == null) {
                // Picks the one that has the minimum sum of the differences between the desired values and
                // the actual values for width and height.
                var minDiff = Integer.MAX_VALUE
                for (sizePair in validPreviewSizes) {
                    val size = sizePair.preview
                    val diff =
                        abs(size.width - DEFAULT_REQUESTED_CAMERA_PREVIEW_WIDTH) +
                                abs(size.height - DEFAULT_REQUESTED_CAMERA_PREVIEW_HEIGHT)
                    if (diff < minDiff) {
                        selectedPair = sizePair
                        minDiff = diff
                    }
                }
            }

            return selectedPair
        }
    }
}
